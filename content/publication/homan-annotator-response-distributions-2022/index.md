---
title: Annotator Response Distributions as a Sampling Frame
authors:
- Christopher Homan
- Tharindu Cyril Weerasooriya
- Lora Aroyo
- Chris Welty
date: '2022-01-01'
publishDate: '2024-10-09T01:52:52.018518Z'
publication_types:
- paper-conference
publication: '*Proceedings of the 1st Workshop on Perspectivist Approaches to NLP
  @LREC2022*'
abstract: Annotator disagreement is often dismissed as noise or the result of poor
  annotation process quality. Others have argued that it can be meaningful. But lacking
  a rigorous statistical foundation, the analysis of disagreement patterns can resemble
  a high-tech form of tea-leaf-reading. We contribute a framework for analyzing the
  variation of per-item annotator response distributions to data for humans-in-the-loop
  machine learning. We provide visualizations for, and use the framework to analyze
  the variance in, a crowdsourced dataset of hard-to-classify examples of the OpenImages
  archive.
url_pdf: 
  http://lrec-conf.org/proceedings/lrec2022/workshops/NLPerspectives/pdf/2022.nlperspectives-1.8.pdf
---
